
# Gesture and Mathematical Symbol Recognition System ğŸ–ï¸â—

A real-time computer vision system that recognizes hand gestures and dynamically drawn mathematical symbols using MediaPipe and Machine Learning. The system integrates static gesture recognition and trajectory-based symbol recognition with confidence estimation.

---

# ğŸ“Œ Project Overview

This project provides an intuitive, touchless interface for interacting with computers using hand gestures and mathematical symbol drawing.

The system uses MediaPipe to extract 21 precise hand landmarks and applies Machine Learning models to classify:

- Static hand gestures
- Dynamically drawn mathematical symbols

Two independent recognition pipelines are integrated into one unified system.

---

# ğŸš€ Key Features

## Real-time Gesture Recognition

Recognizes gestures including:

- Left
- Right
- Up
- Down
- Palm
- Backward Palm
- Peace
- Yo

Features:

- Real-time prediction
- Confidence percentage display
- Landmark normalization (scale and translation invariant)
- Stable prediction using temporal smoothing
- Works with both left and right hand

---

## Mathematical Symbol Recognition

Recognizes dynamically drawn mathematical symbol:

- Integral (âˆ«)

Features:

- Fingertip trajectory tracking using MediaPipe
- Real-time drawing visualization
- Trajectory normalization
- Machine learning based classification
- Confidence percentage output

---

## Dual Mode Operation

The system has two independent modes:

### Gesture Mode
Activated by pressing 1

-Detects static hand gestures with confidence.


### Symbol Mode
Activated by pressing 2

Allows drawing symbol using index finger.

Controls:

|Key| Function |
|---|----------|
| 1 | Activate gesture mode |
| 2 | Activate symbol mode |
| S | Start drawing symbol |
| E | Stop drawing and detect symbol |
| Q | Quit system |

---

# ğŸ§  System Architecture

The system consists of two independent machine learning pipelines.

---

## Static Gesture Recognition Pipeline

Input:

- 21 hand landmarks (x, y, z)

Processing:

- Translation normalization (relative to wrist)
- Scale normalization
- Feature scaling using StandardScaler

Model:

- K-Nearest Neighbors (KNN)

Output:

- Gesture label
- Confidence percentage

---

## Dynamic Symbol Recognition Pipeline

Input:

- Fingertip trajectory sequence

Processing:

- Trajectory normalization
- Fixed-length encoding
- Feature scaling using StandardScaler

Model:

- K-Nearest Neighbors (KNN)

Output:

- Symbol label
- Confidence percentage

---

# ğŸ› ï¸ Tech Stack

Language:

- Python 3.11

Computer Vision:

- OpenCV
- MediaPipe

Machine Learning:

- Scikit-learn (KNN)

Data Processing:

- NumPy
- Pandas

Development Environment:

- VS Code

---

# ğŸ“‚ Project Structure

gesture_project/
â”‚
â”œâ”€â”€ train_knn.py
â”œâ”€â”€ test_knn.py
â”œâ”€â”€ train_dynamic_gesture_model.py
â”‚
â”œâ”€â”€ static_landmarks_dataset_collector.py
â”œâ”€â”€ dynamic_landmarks_dataset_collector.py
â”‚
â”œâ”€â”€ gesture_knn_model.pkl
â”œâ”€â”€ gesture_scaler.pkl
â”œâ”€â”€ class_names_knn.json
â”‚
â”œâ”€â”€ dynamic_gesture_model.pkl
â”œâ”€â”€ dynamic_gesture_scaler.pkl
â”œâ”€â”€ dynamic_gesture_classes.json
â”‚
â”œâ”€â”€ gesture_landmarks.csv
â”œâ”€â”€ dynamic_landmarks_dataset.csv

# â–¶ï¸ How to Run

Run the system using:

python test_knn.py

# ğŸ‘¤ Author

Alankar Akinchan